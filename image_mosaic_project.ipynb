{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_mosaic_project.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM7spm3YdNMAA89MQSOTdv9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amcheyre-nw/image_mosaic_CV/blob/main/image_mosaic_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCyqGt4coakQ",
        "outputId": "4ca7907f-d184-4f59-bb35-7560b970f258"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Usage:   \n",
            "  pip3 install [options] <requirement specifier> [package-index-options] ...\n",
            "  pip3 install [options] -r <requirements file> [package-index-options] ...\n",
            "  pip3 install [options] [-e] <vcs project url> ...\n",
            "  pip3 install [options] [-e] <local project path> ...\n",
            "  pip3 install [options] <archive url/path> ...\n",
            "\n",
            "no such option: -u\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python-headless==4.1.2.30 -quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.lines as mlines\n",
        "import math"
      ],
      "metadata": {
        "id": "EWcbQJQ0or4m"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BT1f6lkvs8hy",
        "outputId": "b2ea856b-7143-4d05-a949-f3532d6c17e8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files_dir = '/content/drive/MyDrive/CV_Project/sample_images'"
      ],
      "metadata": {
        "id": "15dHxMTwtHEl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def homography(image_a, image_b):\n",
        "    \"\"\"Returns the homography mapping image_b into alignment with image_a.\n",
        "    Arguments:\n",
        "      image_a: A grayscale input image.\n",
        "      image_b: A second input image that overlaps with image_a.\n",
        "    Returns: the 3x3 perspective transformation matrix (aka homography)\n",
        "             mapping points in image_b to corresponding points in image_a.\n",
        "    \"\"\"\n",
        "    #sift = cv2.SIFT()\n",
        "    sift = cv2.xfeatures2d.SIFT_create()\n",
        "    kp1, des1 = sift.detectAndCompute(image_a, None)\n",
        "    kp2, des2 = sift.detectAndCompute(image_b, None)\n",
        "\n",
        "    FLANN_INDEX_KDTREE = 0\n",
        "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
        "    search_params = dict(checks=50)\n",
        "\n",
        "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "\n",
        "    matches = flann.knnMatch(des1, des2, k=2)\n",
        "\n",
        "    good = []\n",
        "    for m, n in matches:\n",
        "        if (m.distance / n.distance) < 0.7:\n",
        "            good.append(m)\n",
        "\n",
        "    dst_pts = np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
        "    src_pts = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
        "\n",
        "    M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
        "    matchesMask = mask.ravel().tolist()\n",
        "\n",
        "    h, w = image_a.shape\n",
        "    pts = np.float32([[0, 0],\n",
        "                      [0, h - 1],\n",
        "                      [w - 1, h - 1],\n",
        "                      [w - 1, 0]]).reshape(-1, 1, 2)\n",
        "    dst = cv2.perspectiveTransform(pts, M)\n",
        "\n",
        "    return M"
      ],
      "metadata": {
        "id": "-EjS_mV4pEeS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def warp_image(image, homography):\n",
        "    \"\"\"Warps 'image' by 'homography'\n",
        "    Arguments:\n",
        "      image: a 3-channel image to be warped.\n",
        "      homography: a 3x3 perspective projection matrix mapping points\n",
        "                  in the frame of 'image' to a target frame.\n",
        "    Returns:\n",
        "      - a new 4-channel image containing the warped input, resized to contain\n",
        "        the new image's bounds. Translation is offset so the image fits exactly\n",
        "        within the bounds of the image. The fourth channel is an alpha channel\n",
        "        which is zero anywhere that the warped input image does not map in the\n",
        "        output, i.e. empty pixels.\n",
        "      - an (x, y) tuple containing location of the warped image's upper-left\n",
        "        corner in the target space of 'homography', which accounts for any\n",
        "        offset translation component of the homography.\n",
        "    \"\"\"\n",
        "\n",
        "    p1 = np.ones(3, np.float32)\n",
        "    p2 = np.ones(3, np.float32)\n",
        "    p3 = np.ones(3, np.float32)\n",
        "    p4 = np.ones(3, np.float32)\n",
        "\n",
        "    (y, x) = image.shape[:2]\n",
        "\n",
        "    p1[:2] = [0, 0]\n",
        "    p2[:2] = [x, 0]\n",
        "    p3[:2] = [0, y]\n",
        "    p4[:2] = [x, y]\n",
        "\n",
        "    min_x = None\n",
        "    min_y = None\n",
        "    max_x = None\n",
        "    max_y = None\n",
        "\n",
        "    for pt in [p1, p2, p3, p4]:\n",
        "        hp = np.dot(np.matrix(homography, np.float32),\n",
        "                    np.matrix(pt, np.float32).T)\n",
        "\n",
        "        hp_arr = np.array(hp, np.float32)\n",
        "\n",
        "        normal_pt = np.array([[hp_arr[0] / hp_arr[2]],\n",
        "                             hp_arr[1] / hp_arr[2]], np.float32)\n",
        "\n",
        "        if(max_x is None or normal_pt[0, 0] > max_x):\n",
        "            max_x = normal_pt[0, 0]\n",
        "\n",
        "        if(max_y is None or normal_pt[1, 0] > max_y):\n",
        "            max_y = normal_pt[1, 0]\n",
        "\n",
        "        if(min_x is None or normal_pt[0, 0] < min_x):\n",
        "            min_x = normal_pt[0, 0]\n",
        "\n",
        "        if(min_y is None or normal_pt[1, 0] < min_y):\n",
        "            min_y = normal_pt[1, 0]\n",
        "\n",
        "    translationMatrix = np.zeros(shape=(3, 3))\n",
        "    translationMatrix[0] = [0, 0, -min_x]\n",
        "    translationMatrix[1] = [0, 0, -min_y]\n",
        "    newHomography = np.add(homography, translationMatrix)\n",
        "\n",
        "    warp = cv2.warpPerspective(image,\n",
        "                               newHomography,\n",
        "                               (int(max_x - min_x), int(max_y - min_y)))\n",
        "\n",
        "    return warp, (int(min_x), int(min_y))"
      ],
      "metadata": {
        "id": "D7WBq6YYpJq1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_mosaic(images, origins):\n",
        "    \"\"\"Combine multiple images into a mosaic.\n",
        "    Arguments:\n",
        "      images: a list of 4-channel images to combine in the mosaic.\n",
        "      origins: a list of the locations upper-left corner of each image in\n",
        "               a common frame, e.g. the frame of a central image.\n",
        "    Returns: a new 4-channel mosaic combining all of the input images. pixels\n",
        "             in the mosaic not covered by any input image should have their\n",
        "             alpha channel set to zero.\n",
        "    \"\"\"\n",
        "    # This will make the first image, in the images list,\n",
        "    # have an origin of (0,0)\n",
        "    # so that we can stitch them sequentially.\n",
        "    new_origins = []\n",
        "    o_x, o_y = origins[0]\n",
        "    for origin in origins:\n",
        "        x, y = origin\n",
        "        new_origins.append([x + abs(o_x), y + abs(o_y)])\n",
        "\n",
        "    # Dimensions for the mosaic\n",
        "    max_height = 0\n",
        "    max_width = 0\n",
        "    for image, origin in zip(images, new_origins):\n",
        "        x, y = image.shape[:2]\n",
        "        max_width += origin[0]\n",
        "        max_height += origin[1]\n",
        "\n",
        "    max_width += images[1].shape[1]\n",
        "    max_height += images[1].shape[0]\n",
        "\n",
        "    final = np.ones((max_height, max_width, images[0].shape[2]), np.uint8)\n",
        "    final = cv2.cvtColor(final, cv2.COLOR_BGR2BGRA)\n",
        "\n",
        "    for i in range(len(images)):\n",
        "        y, x, _ = images[i].shape\n",
        "        o_x, o_y = new_origins[i]\n",
        "\n",
        "        final[abs(o_y):abs(y) + abs(o_y),\n",
        "              abs(o_x):abs(x) + abs(o_x), :_] = images[i]\n",
        "\n",
        "    # cv2.imshow('final', final)\n",
        "    # cv2.waitKey(0)\n",
        "    # cv2.destroyAllWindows()\n",
        "    \n",
        "    return final"
      ],
      "metadata": {
        "id": "v0OqHsrEpLb5"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_panoramic(left_path, middle_path, right_path):\n",
        "    \n",
        "    gray_left = cv2.imread(left_path, cv2.IMREAD_GRAYSCALE)\n",
        "    left = cv2.imread(left_path)  # , -1)\n",
        "    gray_middle = cv2.imread(middle_path, cv2.IMREAD_GRAYSCALE)\n",
        "    middle = cv2.imread(middle_path)\n",
        "    # ***middle = cv2.cvtColor(middle, cv2.COLOR_BGR2BGRA)\n",
        "    gray_right = cv2.imread(right_path, cv2.IMREAD_GRAYSCALE)\n",
        "    right = cv2.imread(right_path)  # , -1)\n",
        "    # rows, cols = left_image.shape\n",
        "\n",
        "    # cv2.namedWindow('image', cv2.WINDOW_NORMAL)\n",
        "    # cv2.imshow(\"image\", left_image)\n",
        "    # cv2.waitKey(0)\n",
        "\n",
        "    # compute homography for left image\n",
        "    homography1 = homography(gray_middle, gray_left)\n",
        "    # warp left image\n",
        "    warped_left, origin1 = warp_image(left, homography1)\n",
        "\n",
        "    # compute homography for right image\n",
        "    homography2 = homography(gray_middle, gray_right)\n",
        "    # warp right image\n",
        "    warped_right, origin2 = warp_image(right, homography2)\n",
        "\n",
        "    # print(\"warped_left: \", warped_left.shape)\n",
        "    # print(\"middle: \", middle.shape)\n",
        "    # print(\"warped_right: \", warped_right.shape)\n",
        "\n",
        "    images = (warped_left, warped_right, middle)\n",
        "    origins = (origin1, origin2, (0, 0))\n",
        "    mosaic1 = create_mosaic(images, origins)\n",
        "\n",
        "    cv2.imwrite(\"feetMosaic.png\", mosaic1)"
      ],
      "metadata": {
        "id": "GIRuxjvdrMHR"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "left_path = \"/content/drive/MyDrive/CV_Project/sample_images/DSC_0171.jpeg\"\n",
        "middle_path = \"/content/drive/MyDrive/CV_Project/sample_images/DSC_0172.jpeg\"\n",
        "right_path = \"/content/drive/MyDrive/CV_Project/sample_images/DSC_0173.jpeg\""
      ],
      "metadata": {
        "id": "kbJpMBY5yv91"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_panoramic(left_path, middle_path, right_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "ZSZq6r2crN5y",
        "outputId": "12153dc2-1d46-4592-ac1e-151c9bcf2a13"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-e35b17cfb8d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcreate_panoramic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmiddle_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-b7966bf97c61>\u001b[0m in \u001b[0;36mcreate_panoramic\u001b[0;34m(left_path, middle_path, right_path)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# compute homography for left image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mhomography1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhomography\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray_middle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgray_left\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;31m# warp left image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mwarped_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwarp_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhomography1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-b7cb17300b87>\u001b[0m in \u001b[0;36mhomography\u001b[0;34m(image_a, image_b)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \"\"\"\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#sift = cv2.SIFT()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0msift\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxfeatures2d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIFT_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mkp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdes1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msift\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mkp2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdes2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msift\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv_contrib/modules/xfeatures2d/src/sift.cpp:1207: error: (-213:The function/feature is not implemented) This algorithm is patented and is excluded in this configuration; Set OPENCV_ENABLE_NONFREE CMake option and rebuild the library in function 'create'\n"
          ]
        }
      ]
    }
  ]
}